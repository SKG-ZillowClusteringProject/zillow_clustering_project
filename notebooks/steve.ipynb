{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from env import host, user, password\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import wrangle\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle.zillow17()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"parcelid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"zillow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('zillow.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle.wrangle_zillow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15.0, 8.0)\n",
    "sns.scatterplot(x='home_age', y='logerror',\n",
    "               data=df, hue='county')\n",
    "plt.title(\"How does a homes' age compare to logerror\\nwithin each county?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['structure_dollar_per_sqft'] = df.structure_value / df.sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['land_dollar_per_sqft'] = df.land_value / df.lot_sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bed_bath_ratio'] = df.bedrooms / df.bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.structure_dollar_per_sqft.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15.0, 8.0)\n",
    "sns.scatterplot(x='structure_dollar_per_sqft', y='logerror',\n",
    "               data=df, hue='county')\n",
    "plt.title(\"How does structure value per sqft compare to logerror\\nwithin each county?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.land_dollar_per_sqft.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15.0, 8.0)\n",
    "sns.scatterplot(x='land_dollar_per_sqft', y='logerror',\n",
    "               data=df, hue='county')\n",
    "plt.title(\"How does a land cost per sqft compare to logerror\\nwithin each county?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bed_bath_ratio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15.0, 8.0)\n",
    "sns.scatterplot(x='bed_bath_ratio', y='logerror',\n",
    "               data=df, hue='county')\n",
    "plt.title(\"How does the ratio between bedrooms and bathrooms compare to logerror\\nwithin each county?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"land_dollar_per_sqft\", y=\"logerror\", col=\"county\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['logerror']<-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['logerror'] < -1].fips.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.logerror_quartiles.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower sqft and logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sqft.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['sqft'] < 1500].logerror.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_binned'] = pd.qcut(df.sqft, q=3, labels=['sm_sqft', 'med_sqft', 'lg_sqft'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sqft_binned.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8.0, 15.0)\n",
    "sns.scatterplot(x='logerror', y='home_age',\n",
    "               data=df, hue='sqft_binned')\n",
    "plt.title(\"How does the ratio between bedrooms and bathrooms compare to logerror\\nwithin each county?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars=[\"logerror\", \"sqft\", \"sqft_binned\", \"zip_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_exploration(train, x_string, y_string):\n",
    "    '''\n",
    "    This function takes in a df, a string for an x-axis variable in the df, \n",
    "    and a string for a y-axis variable in the df and displays a scatter plot, the r-\n",
    "    squared value, and the p-value. It explores the correlation between input the x \n",
    "    and y variables.\n",
    "    '''\n",
    "    r, p = stats.pearsonr(train[x_string], train[y_string])\n",
    "    df.plot.scatter(x_string, y_string)\n",
    "    plt.title(f\"{x_string}'s Relationship with {y_string}\")\n",
    "    print(f'The p-value is: {p}. There is {round(p,3)}% chance that we see these results by chance.')\n",
    "    print(f'r = {round(r, 2)}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_exploration(df, 'sqft', 'logerror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.sqft_binned == 'sm_sqft'].logerror.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.sqft_binned == 'med_sqft'].logerror.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.sqft_binned == 'lg_sqft'].logerror.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.assessmentyear.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, target_var):\n",
    "    '''\n",
    "    This function takes in the dataframe and target variable name as arguments and then\n",
    "    splits the dataframe into train (56%), validate (24%), & test (20%)\n",
    "    It will return a list containing the following dataframes: train (for exploration), \n",
    "    X_train, X_validate, X_test, y_train, y_validate, y_test\n",
    "    '''\n",
    "    # split df into train_validate (80%) and test (20%)\n",
    "    train_validate, test = train_test_split(df, test_size=.20, random_state=123)\n",
    "    # split train_validate into train(70% of 80% = 56%) and validate (30% of 80% = 24%)\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=123)\n",
    "\n",
    "    # create X_train by dropping the target variable \n",
    "    X_train = train.drop(columns=[target_var])\n",
    "    # create y_train by keeping only the target variable.\n",
    "    y_train = train[[target_var]]\n",
    "\n",
    "    # create X_validate by dropping the target variable \n",
    "    X_validate = validate.drop(columns=[target_var])\n",
    "    # create y_validate by keeping only the target variable.\n",
    "    y_validate = validate[[target_var]]\n",
    "\n",
    "    # create X_test by dropping the target variable \n",
    "    X_test = test.drop(columns=[target_var])\n",
    "    # create y_test by keeping only the target variable.\n",
    "    y_test = test[[target_var]]\n",
    "\n",
    "    partitions = [train, X_train, X_validate, X_test, y_train, y_validate, y_test]\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = split(df, target_var='logerror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the variables that still need scaling\n",
    "scaled_vars = ['sm_sqft', 'lg_sqft', 'home_age', 'structure_dollar_per_sqft']\n",
    "\n",
    "# create new column names for the scaled variables by adding 'scaled_' to the beginning of each variable name \n",
    "scaled_column_names = ['scaled_' + i for i in scaled_vars]\n",
    "\n",
    "# select the X partitions: [X_train, X_validate, X_test]\n",
    "X = partitions[1:4]\n",
    "\n",
    "# fit the standardscaler to X_train\n",
    "X_train = X[0]\n",
    "scaler = StandardScaler(copy=True).fit(X_train[scaled_vars])\n",
    "\n",
    "\n",
    "def scale_and_concat(df):\n",
    "    scaled_array = scaler.transform(df[scaled_vars])\n",
    "    scaled_df = pd.DataFrame(scaled_array, columns=scaled_column_names, index=df.index.values)\n",
    "    return pd.concat((df, scaled_df), axis=1)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    X[i] = scale_and_concat(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
